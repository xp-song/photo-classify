---
title: "Automated image classification into content-type categories"
subtitle: "Classify images based on keywords generated from the Google Cloud Vision API"
author: "Song, Xiao Ping"
date: 2019
output:
  html_document:
    keep_md: true
    toc: true
    toc_depth: 2
    toc_float: true
    theme: lumen
params:
  data: "photos"
---

```{r housekeeping, echo = FALSE, results='hide', message=FALSE}
library(knitr)
library(kableExtra)
```
&nbsp;

This tutorial describes the workflow and R code that can be used to classify a large number of images into *discrete* categories, based on their content. The source documents are available on [GitHub](<https://github.com/xp-song/photo-classify>), and the interactive HTML is viewable [here](http://htmlpreview.github.io/?https://github.com/xp-song/photo-classify/blob/master/Photo_classification.html). This tutorial provides supplementary information to the following publication:

Song, X.P., Richards, D.R., Tan, P.Y. (2019). Using social media user attributes to understand humanâ€“environment interactions at urban parks (in review).  

An earlier iteration of the code was used in [this publication](https://doi.org/10.1016/j.ecoser.2017.09.004). Note that there are [numerous other ways to classify images](https://doi.org/10.1016/J.ECOLIND.2018.08.035), including those that deal with overlapping content.

&nbsp;

***

The dataset ``r params$data`` is used as an example. It contains 50 photos with a column of photo *source* URLs. These are sent to the Google Cloud Vision Application Programming Interface (API), to generate up to ten keyword labels per photo.

Note that you will need to have signed-up with the Google Cloud Platform and generated your Client ID and Client secret. We will be using the [googleAuthR](https://cran.r-project.org/web/packages/googleAuthR/index.html) and [RoogleVision](https://github.com/cloudyr/RoogleVision) packages to interact with the API.

&nbsp;

First few rows of the `photos` dataset:
```{r example_df, echo = FALSE}
photos <- structure(list(photoid = c("29993180834", "7002246829", "5466070643", 
"16303185765", "30414187771", "16065397248", "15838870660", "6124041938", 
"6044837037", "8246481270", "16118419457", "16118617130", "16756672194", 
"34428418792", "27046221503", "5062768408", "5377955989", "5941941084", 
"24992311348", "22995022122", "8697765913", "3391983590", "6932019807", 
"14776830698", "27245858161", "32451895655", "7120977017", "35835403985", 
"24466157047", "7714129040", "34060774091", "6702436399", "2785023233", 
"4528642435", "1917685629", "32794263654", "19434109561", "5417929118", 
"5354272778", "26432228932", "7944118682", "27001300481", "8274335606", 
"29779420582", "8305630989", "2464844430", "6803037514", "2766604449", 
"3668360066", "6093643238"), url = c("https://farm6.staticflickr.com/5641/29993180834_8179c87aa7_z.jpg", 
"https://farm7.staticflickr.com/6240/7002246829_d114f402e7_z.jpg", 
"https://farm6.staticflickr.com/5216/5466070643_759428f4a5_z.jpg", 
"https://farm9.staticflickr.com/8571/16303185765_4dd4d48b7b_z.jpg", 
"https://farm6.staticflickr.com/5503/30414187771_5283977ca6_z.jpg", 
"https://farm9.staticflickr.com/8593/16065397248_7a6a0666b1_z.jpg", 
"https://farm9.staticflickr.com/8586/15838870660_305d0a3a16_z.jpg", 
"https://farm7.staticflickr.com/6086/6124041938_5a960a0284_z.jpg", 
"https://farm7.staticflickr.com/6074/6044837037_420af3f5ec_z.jpg", 
"https://farm9.staticflickr.com/8197/8246481270_ba01f47f3c_z.jpg", 
"https://farm9.staticflickr.com/8588/16118419457_fa9ae17eee_z.jpg", 
"https://farm9.staticflickr.com/8662/16118617130_29e43fa1aa_z.jpg", 
"https://farm8.staticflickr.com/7715/16756672194_d67158e5f4_z.jpg", 
"https://farm5.staticflickr.com/4163/34428418792_032ddcff29_z.jpg", 
"https://farm8.staticflickr.com/7056/27046221503_9b5bf5ee24_z.jpg", 
"https://farm5.staticflickr.com/4104/5062768408_9e55038330_z.jpg", 
"https://farm6.staticflickr.com/5121/5377955989_dc690f66fe_z.jpg", 
"https://farm7.staticflickr.com/6030/5941941084_2c6edbc2eb_z.jpg", 
"https://farm5.staticflickr.com/4546/24992311348_785d9c25ca_z.jpg", 
"https://farm6.staticflickr.com/5811/22995022122_38d8458d12_z.jpg", 
"https://farm9.staticflickr.com/8273/8697765913_5c99c640c6_z.jpg", 
"https://farm4.staticflickr.com/3537/3391983590_e8bf5333e3_z.jpg", 
"https://farm8.staticflickr.com/7189/6932019807_a64a81aab7_z.jpg", 
"https://farm4.staticflickr.com/3848/14776830698_c4fe43d534_z.jpg", 
"https://farm8.staticflickr.com/7071/27245858161_fc0d1ee905_z.jpg", 
"https://farm1.staticflickr.com/438/32451895655_d8c5c1e969_z.jpg", 
"https://farm8.staticflickr.com/7208/7120977017_24c6d2b215_z.jpg", 
"https://farm5.staticflickr.com/4289/35835403985_d9d069c6fb_z.jpg", 
"https://farm5.staticflickr.com/4735/24466157047_8747fcf558_z.jpg", 
"https://farm8.staticflickr.com/7132/7714129040_b8c1822798_z.jpg", 
"https://farm3.staticflickr.com/2891/34060774091_35363d902a_z.jpg", 
"https://farm8.staticflickr.com/7159/6702436399_55e0ee20a2_z.jpg", 
"https://farm4.staticflickr.com/3071/2785023233_cd5ef913b7_z.jpg", 
"https://farm5.staticflickr.com/4062/4528642435_7218195cea_z.jpg", 
"https://farm3.staticflickr.com/2015/1917685629_234cc23fa4_z.jpg?zz=1", 
"https://farm4.staticflickr.com/3940/32794263654_9b76c7d71f_z.jpg", 
"https://farm1.staticflickr.com/556/19434109561_f2fff4167b_z.jpg", 
"https://farm6.staticflickr.com/5299/5417929118_46aa551d4d_z.jpg", 
"https://farm6.staticflickr.com/5169/5354272778_3532b709c7_z.jpg", 
"https://farm2.staticflickr.com/1552/26432228932_c4400a6937_z.jpg", 
"https://farm9.staticflickr.com/8174/7944118682_2e059ae626_z.jpg", 
"https://farm8.staticflickr.com/7419/27001300481_985acfa187_z.jpg", 
"https://farm9.staticflickr.com/8060/8274335606_6bc423cbaf_z.jpg", 
"https://farm6.staticflickr.com/5603/29779420582_659c41cca1_z.jpg", 
"https://farm9.staticflickr.com/8079/8305630989_d785d24a83_z.jpg", 
"https://farm3.staticflickr.com/2175/2464844430_29a2429008_z.jpg?zz=1", 
"https://farm8.staticflickr.com/7195/6803037514_86235970de_z.jpg", 
"https://farm4.staticflickr.com/3240/2766604449_0cfe0bab28_z.jpg", 
"https://farm4.staticflickr.com/3351/3668360066_dd121e5fcb_z.jpg", 
"https://farm7.staticflickr.com/6073/6093643238_e0c8357471_z.jpg"
)), .Names = c("photoid", "url"), row.names = c(NA, -50L), class = "data.frame")


kable(head(photos)) %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "responsive"), full_width = T)
```

&nbsp;

Plug-in your Google Cloud Platform credentials:
```{r gcp_housekeeping, results='hide', message=FALSE, eval = FALSE}
require(googleAuthR)

options("googleAuthR.client_id" = "xxx.apps.googleusercontent.com")
options("googleAuthR.client_secret" = "")

options("googleAuthR.scopes.selected" = c("https://www.googleapis.com/auth/cloud-platform"))
googleAuthR::gar_auth() #You will be directed to a weblink to sign-in with your account
```

&nbsp;

***

# Generate Keywords 

Create a loop to send each photo URL to the Google Cloud Vision API, and append the results to ``r params$data``:
```{r keyword_gen, eval = FALSE}
require(RoogleVision) 

#add extra columns for 10 x 3 rows of data (keyword, probability score, and topicality score)
photos[,3:32] <- NA

##Loop##
for(i in 1:length(photos$url)){ 

  te <- getGoogleVisionResponse(photos$url[i], feature="LABEL_DETECTION", numResults = 10)
  
  #If not successful, return NA matrix
  if(length(te)==1){ te <- matrix(NA, 10,4)} 
  if (is.null(te)){ te <- matrix(NA, 10,4)}
  
  te <- te[,2:4]
  
  #if successful but no. of keywords <10, put NAs in remaining rows
  if(length(te[,1])<10){
    te[(length(te[,1])+1):10,] <- NA}  
  
  #Append all data!
  photos[i, 3:12] <- te[,1] #keywords
  photos[i, 13:22] <- te[,2] #probability scores
  photos[i, 23:32] <- te[,3] #topicality scores
  
  cat("<row", i, "/", length(photos[,1]), "> ")
  }
```

```{r eval=FALSE, echo = FALSE, results='hide', message=FALSE}
##tidy up##
names(photos)[3:32] <- c("w1", "w2", "w3", "w4", "w5", "w6", "w7", "w8", "w9", "w10",
                        "p1", "p2","p3","p4","p5", "p6", "p7", "p8", "p9", "p10",
                        "t1", "t2","t3","t4","t5", "t6", "t7", "t8", "t9", "t10")

#Save file
write.csv(photos, "data/GCV.csv")
```

&nbsp;

Keyword results for the first few rows of the `photos` dataset:
```{r keywords_eg, echo = FALSE, rownames.print = FALSE, cols.print = 5}
photos <- read.csv("data/GCV.csv", stringsAsFactors = FALSE)
photos <- photos[ , !names(photos) %in% "X"]

kable(head(photos[,3:12])) %>%
  kable_styling(bootstrap_options = c("striped", "condensed", "responsive"), full_width = T, font_size = 12)

```

&nbsp;

***

# Classify Photos {.tabset .tabset-fade .tabset-pills}
Next, we prepare the keywords to be used for hierarchical cluster analysis (HCA) of photos. HCA tends to be very memory intensive. Thus, depending on the number of photos you have, you may want to run the following code on a high performance computing cluster. Parallel computing can be used to speed up memory-intensive loops, using the R packages [foreach](https://cran.r-project.org/web/packages/foreach/index.html) and [doParallel](https://cran.r-project.org/web/packages/doParallel/index.html).

&nbsp;

Set-up your machine for parallel computing:
```{r parallelise, results=FALSE, message=FALSE}
require(foreach)
require(doParallel)

#setup parallel backend to use many processors
cat("Number of cores = ", detectCores())
cl <- makeCluster(detectCores(), outfile=paste0('./admin/info_parallel.log')) #log file with info
registerDoParallel(cl)
rm(cl)
```

&nbsp;

Before we begin clustering the entire dataset, however, we need to find out how many clusters to group the photos into. If your dataset is large, it may be better to first test the outcomes of different numbers of clusters on a __*subset*__ of your data.  _If so, proceed with the following **two** sub-sections on a **random subset** of your data, before re-running the **first** sub-section (**A. Distance matrix and clustering**) the with the **full** dataset._

&nbsp;

***

## A. Distance matrix and clustering 

Extract all the unique keywords across ``r params$data`` (or subset of ``r params$data``):
```{r unique_keywords, message = FALSE}
words <- unlist(photos[,3:12])
words <- words[!duplicated(words)] #list of unique keywords
```
&nbsp;

Next, we convert ``r params$data`` into a binary format and name it `wordscore`, with each row representing a photo, and each column representing a keyword. "1" is added if the word is present. We then convert `wordscore` into a sparse matrix. This will help reduce the load on the computer's RAM, especially if the photo dataset is very large.
```{r convert_binary, message = FALSE}
#parallel loop:
wordscore <- foreach(i = 1:length(photos[,1]), .combine=rbind) %dopar% {
  vec <- vector(mode = "integer",length = length(words))
  a <- match(photos[i,3:12], words)
  vec[a] <- 1
  
  cat(paste0(" row ", i), file=paste0("admin/log_wordscore.txt"), append=TRUE) #The loop's progress will be printed in this file
  vec
}
colnames(wordscore) <- words
rownames(wordscore) <- NULL
wordscore <- wordscore[,!is.na(colnames(wordscore))] #remove 'NA' keyword if present

library(Matrix) 
wordscore <- Matrix(wordscore, sparse = TRUE)  #convert to sparseMatrix to save memory
```
&nbsp;

In the binary format, `wordscore` can now be converted into a distance matrix. To have a fair assessment of the similarity (and thus the distance) between two photos, we need to take into account if they have the same number of keywords generated. The Jaccard Index is used in the calculation, where the number of common keywords is divided by the total number of unique keywords between two photos. 

To start with, we find out how many keywords each photo has (up to ten), and save the results as the vector `lengword`:
```{r make_function, results = 'hide'}
narmlength <- function(x){10-sum(is.na(x))} #create function
lengword <- apply(photos[,3:12], 1, narmlength) #apply function
```

```{r echo = FALSE}
rm(narmlength)
invisible(gc())
```
&nbsp;

Next, the similarity between each photo and all other photos is calculated manually in a loop, based on the Jaccard Index. Since most photos do not share keywords, the similarity value will tend to be "0" (less strain on computer's RAM). The similarity matrix (loop output) is then converted into a distance matrix, and subsequently converted into a 'dist' object.
```{r distmatrix, message = FALSE}
simimat <- foreach(i = 1:length(wordscore[,1]), .packages = "Matrix", .combine=cbind) %dopar% {
  
  ws <- wordscore[,which(wordscore[i,] == 1)] #for each photo, find the other photos (rows) with its keywords (cols)
  
  simi <- round(apply(as.matrix(ws),1,sum, na.rm=T)/(lengword+lengword[i]),2) #Jaccard index
  
  simi[1:i] <- 0 #only fill half the matrix
  simi[i] <- 1
  
  cat(paste("row",i), file=paste0("admin/log_simimat.txt"), append=TRUE)
  
  simi
}

colnames(simimat) <- NULL
rm(wordscore, lengword)


#convert similarity to distance
distmat <- 1-simimat
rm(simimat)

#Convert to a 'dist' object
dm <- as.dist(distmat)
```

&nbsp;

Finally, we perform hierarchical clustering of photos, using Ward's distance:
```{r clustering, results = 'hide', message=FALSE}
require(fastcluster)
require(graphics)

cluz <- fastcluster::hclust(dm, "ward.D2")
```
&nbsp;

_Go to '**B. How many clusters?**' if the number of photo categories has not been determined._

&nbsp;

***

## B. How many clusters? 
This section runs as a separate analysis from the final results. Note that the following script may take a long time to run if you have a large dataset.

In this analysis, we measure the average difference between within- and between-cluster variation, across different clustering scenarios. Thus, a higher value suggests distinct clusters that more 'different' from each other (i.e. greater variation/distance between clusters). As the number of clusters (*k*) increases, this value is expected to decrease. We plot these values, and use the L-Method to find the 'knee' of the evaluation graph. More information about the L-Method can be found at:

Salvador, S. & Chan, P. Determining the Number of Clusters / Segments in Hierarchical Clustering / Segmentation Algorithms. in 16th *IEEE International Conference on Tools with Artificial Intelligence* 576-584 (IEEE, 2004). doi:10.1109/ICTAI.2004.50

&nbsp;

First, decide up to how many clusters (*k*) to test for. In this example, we test *k* from 2 to 20, and save it as the vector `scenarios` (19 scenarios):
```{r define_k}
scenarios <- numeric(length(2:20))
```
&nbsp;

Create a function to measure the difference between within- and between-cluster variation across all photos. Run the function for different *k* values in `scenarios`.
```{r function_differ, results = 'hide', message = FALSE}

differ <- function(dist, gr, pos){
  #dist is a single photo's vector of distances with all others
  #gr is the vector output of grp membership across all photos
  #pos is the position of the single photo in length(distmat[1,])
  
  gr2 <-numeric(length(gr)) #vector of "0"s
  gr2[gr==gr[pos]] <-1 #Which photos are in same cluster as the photo of interest?
  gr3 <- 1-tapply(dist,gr2, mean) #2 values generated: (1) mean distance compared to photos in other clusters, & (2) compared to photos within same cluster. Minus values from one to convert to similarity value.
  gr3[2]-gr3[1] #within-cluster minus between-cluster similarity (larger value means clusters are very different)
}


#Run function for different scenarios (numbers of clusters):
for(i in 2:(length(scenarios)+1)){
  grp <- cutree(cluz, k=i)  #cutree returns vector of grp memberships across all photos
  
  cat("\n<< Working on scenario k =", i, "/", (length(scenarios)+1), ">>\n")
  
  alldiffer <-numeric(length(distmat[,1])) #vector of "0"s"
  
  for(j in 1:length(distmat[,1])){ #run function for each photo (across rows)
    alldiffer[j]<- differ(distmat[j,], grp, j )
    
    cat("<row", j, "/", length(distmat[,1]), "photos>")
    
  }
  scenarios[i-1]<-mean(alldiffer) #find out the mean difference for each scenario (k)
  
  cat("\n<< Scenario k =", i, "COMPLETE >>")
}


#Create dataframe
scenarios <- cbind.data.frame(seq(2,(length(scenarios)+1),1), 1-scenarios) #convert to distance
colnames(scenarios) <- c("k", "distance")
```

Do note that the small number of photos in our example produces a relatively straight curve. To help with visualisation, we can also calculate the marginal change in the distance:
```{r marginal_change, results = 'hide', message = FALSE}
for(i in 2:length(scenarios$distance)){
  scenarios[i,3] <- scenarios$distance[i-1]-scenarios$distance[i]
}

colnames(scenarios) <- c("k","distance","marginalDelta")
```
&nbsp;

```{r echo = FALSE}
captions <- c("Average value between clusters","Marginal change in value")
#for figure in next section
```

Here are plots of the results across different clustering scenarios:
```{r clusteringscenarios_results, echo=FALSE, warning=FALSE,  comment=FALSE, message= FALSE, eval=T, fig.height = 3, fig.width = 3,  fig.align = "center", fig.cap="Differences between within- and between-cluster variation, across different clustering scenarios", fig.subcap=captions, fig.asp=1, fig.ncol = 2}

library(ggplot2)

scenarios %>%
  ggplot(aes(x=k,y=distance))+
  geom_point()+
  geom_line()+
  xlab("Number of clusters (k)") +
  ylab("Avg distance between clusters")

scenarios %>%
  ggplot(aes(x=k,y=marginalDelta))+
  geom_point()+
  geom_line()+
  xlab("Number of clusters (k)") +
  ylab("Marginal change in distance")
```
&nbsp;

Since such plots may not always allow us to visually determine the appropriate number of photo clusters, we can also use the L-Method as described in Salvador and Chan (2004). To do so, we plot possible pairs of best-fit lines to the curve, and calculate the total root mean squared error (RMSE) for each pair. The lowest RMSE value is used to determine the number of clusters.

```{r echo = FALSE, results='hide', message=FALSE}
#packages 'rgl' and 'qpcR' require 'shiny' to be installed
#install.packages("shiny", type = "binary", dependencies = TRUE)
#require(shiny)
```

Note that for the 'RMSE' function that we use in this section, loading the packages requires [XQuartz](https://www.xquartz.org/) to be installed if you're using a Mac.
```{r lmethod, message=FALSE, results = 'hide'}
require(rgl)
require(qpcR)

#Best-fit line equation:
mod1 <- lm(distance ~ k, data = scenarios)


#Equation from Salvador & Chan (2004):
for(i in 3:(max(scenarios$k)-2)){  #lowest value the 'knee' can be at is 3
  rmse <-  ((i-1)/(max(scenarios$k)-1)*(RMSE(mod1, which = 2:i))) + (((max(scenarios$k)-i)/(max(scenarios$k)-1))*RMSE(mod1, which = (i+1):max(scenarios$k)))
scenarios[i-1,4] <- rmse
}

colnames(scenarios) <- c("k","distance", "marginalDelta", "Lrmse")
```
&nbsp;

Now we can plot RMSE across an increasing number of clusters (k). In our example, the lowest RMSE value where k = ``11``. This is the 'knee' of the graph. Note that there are a roughly balanced number of points on either side of this value.
```{r rmse_plot, echo = FALSE, message = FALSE,  warning=FALSE, fig.height = 3, fig.width = 3.5, fig.align = "center", fig.cap="Total RMSE of possible pairs of best-fit lines."}

scenarios %>%
  ggplot(aes(x=k,y=Lrmse))+
  geom_point()+
  geom_line()+
  xlab("Number of clusters (k)") +
  ylab("Root mean squared error")
```

&nbsp;

Now it's time to classify our photos and visualise the categories for good! 
_Go back to '**A. Distance matrix and clustering**' and re-run the script for the full dataset if a subset of data was used to determine the number of clusters._
If not, continue on to the next section...

&nbsp;

***

# Visualise Results
Time to classify the full dataset into ``11`` clusters!
```{r final_clustering, results=FALSE, message=FALSE}

grp <- cutree(cluz, k=11)
photos <- cbind.data.frame(photos, grp, stringsAsFactors = FALSE) #Final dataframe

##Plot##
plot(as.dendrogram(cluz), sub = "", xlab ="", ylab = "Height", main = "Hierarchical clustering of photos into 11 categories", cex.main = 0.95, leaflab = "none")
rect.hclust(cluz, k = 11, border = "red")
```

